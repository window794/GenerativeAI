[
    {
        "number": 1,
        "upper": "ルールベースの内容",
        "lower": "人間が事前に作成したルールや知識をコンピュータ・プログラムに組み込むことで、それに基づいて予測や判断を行う技術"
    },
    {
        "number": 2,
        "upper": "ルールベースの特徴",
        "lower": "複雑な問題に対処するために大量のルールが必要で、そうしたルールの管理が困難"
    },
    {
        "number": 3,
        "upper": "機械学習の内容",
        "lower": "機械（コンピュータ）自身がデータからパターンを見出し、予測や判断を行う技術"
    },
    {
        "number": 4,
        "upper": "機械学習の特徴",
        "lower": "統計的手法やアルゴリズムを用いて、入力した大量のデータから機械が自ら学習"
    },
    {
        "number": 5,
        "upper": "教師あり学習",
        "lower": "正解データのペアを与えて、モデルをトレーニングする"
    },
    {
        "number": 6,
        "upper": "教師なし学習",
        "lower": "正解データのペアを与えず、代わりにデータ自体のパターンや構造をモデルが自己発見する"
    },
    {
        "number": 7,
        "upper": "強化学習",
        "lower": "コンピュータに「報酬」という特定の目標を設定し、その目標を達成するための最適な行動を学習させる"
    },
    {
        "number": 8,
        "upper": "半教師あり学習",
        "lower": "ありなりのハイブリッド。少量の正解データを用いて、大量のラベルのない（未知のデータ）を効率的に学習する"
    },
    {
        "number": 9,
        "upper": "ノーフリーランチ定理",
        "lower": "どの問題にも万能で汎用的なモデルは存在しない"
    },
    {
        "number": 10,
        "upper": "ニューロン",
        "lower": "脳の高度な働きを支えている個々の神経細胞のこと"
    },
    {
        "number": 11,
        "upper": "人工ニューロン（ノード）",
        "lower": "ニューロンをプログラミングで再現したもの"
    },
    {
        "number": 12,
        "upper": "ニューラルネットワーク",
        "lower": "人工ニューロンによる複層的な情報伝達の仕組み"
    },
    {
        "number": 13,
        "upper": "ディープラーニング",
        "lower": "ニューラルネットワークを更に何層にも重ねて作ったシステム"
    },
    {
        "number": 14,
        "upper": "重み",
        "lower": "情報や物事の大切さ自体"
    },
    {
        "number": 15,
        "upper": "重み付け",
        "lower": "人工ニューロン（ノード）がその情報量を調整すること（重要性に差異をつけること）"
    },
    {
        "number": 16,
        "upper": "クラスタリング",
        "lower": "教師なし学習の手法の一つで、与えられたデータに似たパターンを持つグループに分類すること"
    },
    {
        "number": 17,
        "upper": "次元削減",
        "lower": "教師なし学習の手法の一つで、データの次元（変数）を減らすことで、情報を保持しながらデータの特徴を抽出すること"
    },
    {
        "number": 18,
        "upper": "過学習",
        "lower": "モデルが訓練データに適合しすぎてしまい、新しいデータに対する汎化性能が低下する現象のこと"
    },
    {
        "number": 19,
        "upper": "アーリーストッピング",
        "lower": "検証データの誤差が悪化し始めたタイミングで、検証をやめるテクニック"
    },
    {
        "number": 20,
        "upper": "正則化",
        "lower": "重みの大きさにペナルティをかけてシンプルにするテクニック"
    },
    {
        "number": 21,
        "upper": "ドロップアウト",
        "lower": "学習中にランダムに一部のニューロンを無効化して、特定の特徴に依存しすぎないようにするテクニック"
    },
    {
        "number": 22,
        "upper": "転移学習",
        "lower": "AIが1つのタスクから学んだ知識を、別のタスクへと活用する学習方法"
    },
    {
        "number": 23,
        "upper": "ANI",
        "lower": "「特定のタスク」に対して人間並の性能を発揮する"
    },
    {
        "number": 24,
        "upper": "AGI",
        "lower": "「すべての知的タスク」に対して人間並みの性能を発揮する"
    },
    {
        "number": 25,
        "upper": "ダートマス会議",
        "lower": "1956年開催。AI研究の発端となる会議で、「機械が学習し、推論できる方法」を探るために開かれた"
    },
    {
        "number": 26,
        "upper": "シンギュラリティ",
        "lower": "技術的特異点とも。AIが人間を超越し、知能的に自己進化する状態"
    },
    {
        "number": 27,
        "upper": "2045年問題",
        "lower": "2045年頃にシンギュラリティが起こり、AIが人間の知性を超越して、人間が様々な問題や脅威に直面する"
    },
    {
        "number": 28,
        "upper": "AI効果",
        "lower": "AI技術が進歩して日常的に使われるようになることで、もはや「AIではない」と感じられること"
    },
    {
        "number": 29,
        "upper": "レベル1",
        "lower": "単純なプログラム"
    },
    {
        "number": 30,
        "upper": "レベル2",
        "lower": "ルールベースシステムを利用したAI"
    },
    {
        "number": 31,
        "upper": "レベル3",
        "lower": "機械学習を利用したAI"
    },
    {
        "number": 32,
        "upper": "レベル4",
        "lower": "ディープラーニングを利用したAI"
    },
    {
        "number": 33,
        "upper": "ボルツマンマシン",
        "lower": "ニューラルネットワークの一種で、確率的に動作する"
    },
    {
        "number": 34,
        "upper": "制限付きボルツマンマシン",
        "lower": "入力層と隠れ層の2層構造を持ち、層内のニューロン同士の結合を禁止したことで学習を効率化した、確率的生成モデル"
    },
    {
        "number": 35,
        "upper": "ディープラーニング",
        "lower": "人間の脳の働きを模倣した技術で、複雑なパターンを学習する能力"
    },
    {
        "number": 36,
        "upper": "CNN",
        "lower": "畳み込みニューラルネットワーク。画像や時系列データの特徴を自動で抽出するため、畳み込み層とプーリング層を組み合わせたDLのモデル"
    },
    {
        "number": 37,
        "upper": "VAE",
        "lower": "エンコーダとデコーダからなる"
    },
    {
        "number": 38,
        "upper": "エンコーダ",
        "lower": "入力データを潜在変数に圧縮し、分布として表現するネットワーク"
    },
    {
        "number": 39,
        "upper": "デコーダ",
        "lower": "エンコーダで得た潜在変数から本のデータを復元するためのネットワーク"
    },
    {
        "number": 40,
        "upper": "GAN",
        "lower": "敵対的生成ネットワーク。生成器と識別器からなる"
    },
    {
        "number": 41,
        "upper": "生成器",
        "lower": "ランダムノイズラベルや洗剤空間のサンプルを入力として受取、それをもとにデータの生成を試みる役割"
    },
    {
        "number": 42,
        "upper": "識別器",
        "lower": "生成器が生成したデータと本物のデータを区別する役割"
    },
    {
        "number": 43,
        "upper": "RNN",
        "lower": "回帰型ニューラルNW。音楽のような時間的に連続したパターンを持つデータに適した技術だが、長期に渡る情報を扱うには勾配消失の問題が起こり得る"
    },
    {
        "number": 44,
        "upper": "LSTMの課題",
        "lower": "①入力される自然言語があまりにも長文になると精度が下がる\n②時系列での学習になるので、並列学習に向かない\n③大規模データを学習するのには多大な時間がかかる"
    },
    {
        "number": 45,
        "upper": "GPTモデル",
        "lower": "大量のテキストデータを学習して、新しい文章を生成するAI"
    },
    {
        "number": 46,
        "upper": "BERTモデル",
        "lower": "双方向性。文脈を前後から理解する総報告のトランスフォーマーモデルで、自然言語処理の様々なタスクで高精度な予測ができる"
    },
    {
        "number": 47,
        "upper": "RoBERTa",
        "lower": "BERTの役10倍のデータ量と長い時間を使って訓練"
    },
    {
        "number": 48,
        "upper": "ALBERT",
        "lower": "BERTの軽量版で、パラメータ共有や次元削減によってメモリ効率を向上させつつ、高い精度を維持できるモデル"
    },
    {
        "number": 49,
        "upper": "GPT1",
        "lower": "非常に自然な文章の生成が可能"
    },
    {
        "number": 50,
        "upper": "GPT2",
        "lower": "非常に性能が高く、その潜在的な誤用や悪用に関する危険性から、はじめはフルモデルの公開が控えられていた"
    },
    {
        "number": 51,
        "upper": "GPT3",
        "lower": "従来モデルよりも遥かに大規模なモデル"
    },
    {
        "number": 52,
        "upper": "GPT3.5",
        "lower": "3の改良版で、より多様な文章生成と対話が可能。ChatGPTはこれをベースにしている"
    },
    {
        "number": 53,
        "upper": "GPT4",
        "lower": "約1兆7600億もの驚異的なパラメータを持っているとされる"
    },
    {
        "number": 54,
        "upper": "アラインメント",
        "lower": "人間の求める適切な回答を出すように調整していくこと"
    },
    {
        "number": 55,
        "upper": "RHLF",
        "lower": "人間のFBに基づいて出力を矯正する方法"
    },
    {
        "number": 56,
        "upper": "ハルシネーション",
        "lower": "モデルが不正確あるいは誤った情報を、あたかも正しい情報のように生成すること"
    },
    {
        "number": 57,
        "upper": "マルチモーダル",
        "lower": "テキストや画像、音声、動画などの異なる種類のデータを一度に処理することができることが可能なAI技術のこと"
    },
    {
        "number": 58,
        "upper": "テキスト生成AI",
        "lower": "自然言語処理と機械学習の技術を利用して、文章やテキストデータを自動的に生成する技術"
    },
    {
        "number": 59,
        "upper": "NLP",
        "lower": "自然言語処理。コンピュータに人間の言葉を理解させるための技術"
    },
    {
        "number": 60,
        "upper": "画像生成AI",
        "lower": "コンピュータが画像を生成するための技術\n①GAN\n②VAE\n③CNN"
    },
    {
        "number": 61,
        "upper": "音楽生成AI",
        "lower": "コンピュータが音楽を作り出すための技術。MIDIファイルなどの音楽データを含む。\nシーケンスデータの処理に長けているRNNを用いてデータセットの情報を水増しする"
    },
    {
        "number": 62,
        "upper": "音声生成AI",
        "lower": "コンピュータが音声を生成するための技術。トレーニングには一般的には「教師あり学習」が用いられる"
    },
    {
        "number": 63,
        "upper": "動画生成AI",
        "lower": "コンピュータが静止画像を連続的に結合して動画を生成するための技術。主な訓練手法にGANやVAEがある。各フレーム間の一貫性を保つことが大事で、RNNが使用される"
    },
    {
        "number": 64,
        "upper": "スピアフィッシング",
        "lower": "特定の個人や組織を標的にしたフィッシング攻撃の一種。ユーザになりすましてメールなどで悪意のあるリンクや添付ライフを送付することで、情報を窃盗する"
    },
    {
        "number": 65,
        "upper": "ベイト攻撃",
        "lower": "魅力的なソフトウェアや注目のコンテンテンツの提供を「餌」としてターゲットの興味を引き、その結果として情報などを窃盗したりマルウェアをダウンロードさせたりする行為"
    },
    {
        "number": 66,
        "upper": "ブラックメール",
        "lower": "個人や組織に対して何らかの秘密や情報を公にすると脅迫し、金銭などを要求する行為"
    },
    {
        "number": 67,
        "upper": "プレテキスト",
        "lower": "特定の目的を達成するために虚偽の情報や状況を利用してターゲットを騙す行為。攻撃者はターゲットの信頼を得るために、信頼性の高い虚偽のシナリオの前提（プレテキスト）を設定し、それを根拠に情報を要求する"
    },
    {
        "number": 68,
        "upper": "LLM",
        "lower": "LMと比較して非常に大規模なデータセットで学習された自然言語処理モデル"
    },
    {
        "number": 69,
        "upper": "プレトレーニング",
        "lower": "大量のテキストデータを使用して自然言語の知識を獲得するための学習方法。教師なし学習が用いられる"
    },
    {
        "number": 70,
        "upper": "ファインチューニング",
        "lower": "タスク特有のデータやコンテキストに応じた語彙や表現を学習し、タスクの性能を向上させるトレーニングプロセス"
    },
    {
        "number": 71,
        "upper": "ハイパラメータ",
        "lower": "モデル学習前に手動で設定・調整が可能なパラメータ"
    },
    {
        "number": 72,
        "upper": "Zero-Shotプロンプティング",
        "lower": "例示が0個の文章構成で入力を得るもの"
    },
    {
        "number": 73,
        "upper": "Few-Shotプロンプティング",
        "lower": "例示を2~3個入力して質問を行うことで、よりに望ましい回答を得ることを可能とするプロンプティング"
    }
]